apiVersion: apps/v1
kind: Deployment
metadata:
  name: <%= service.name %>
  namespace: <%= project.name %>
  labels:
    caninemanaged: 'true'
    app: <%= service.name %>
spec:
  replicas: <%= service.replicas %>
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 2
  selector:
    matchLabels:
      app: <%= service.name %>
  template:
    metadata:
      labels:
        app: <%= service.name %>
    spec:
      containers:
      - name: <%= project.name %>
        image: <%= project.container_image_reference %>
        imagePullPolicy: Always
        <% if service.command.present? %>
        command: <%= service.command.split.to_json %>
        <% end %>
        envFrom:
        - configMapRef:
            name: <%= project.name %>
        ports:
        - containerPort: <%= service.container_port %>
        <% if service.healthcheck_url.present? %>
        livenessProbe:
          httpGet:
            path: <%= service.healthcheck_url %>
            port: <%= service.container_port %>
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: <%= service.healthcheck_url %>
            port: <%= service.container_port %>
          initialDelaySeconds: 30
          periodSeconds: 10
        <% end %>
        <% if @project.volumes.present? %>
        volumeMounts:
        <% @project.volumes.each do |volume| %>
        - name: <%= volume.name %>
          mountPath: <%= volume.mount_path %>
        <% end %>
        <% end %>
        <% resource_constraint = service.resource_constraint || project.resource_constraint %>
        <% if resource_constraint.present? %>
        resources:
          <% if resource_constraint.cpu_request.present? || resource_constraint.memory_request.present? || resource_constraint.gpu_request.present? %>
          requests:
            <% if resource_constraint.cpu_request.present? %>
            cpu: "<%= resource_constraint.cpu_request_formatted %>"
            <% end %>
            <% if resource_constraint.memory_request.present? %>
            memory: "<%= resource_constraint.memory_request_formatted %>"
            <% end %>
            <% if resource_constraint.gpu_request.present? && resource_constraint.gpu_request > 0 %>
            nvidia.com/gpu: <%= resource_constraint.gpu_request %>
            <% end %>
          <% end %>
          <% if resource_constraint.cpu_limit.present? || resource_constraint.memory_limit.present? %>
          limits:
            <% if resource_constraint.cpu_limit.present? %>
            cpu: "<%= resource_constraint.cpu_limit_formatted %>"
            <% end %>
            <% if resource_constraint.memory_limit.present? %>
            memory: "<%= resource_constraint.memory_limit_formatted %>"
            <% end %>
            <% if resource_constraint.gpu_request.present? && resource_constraint.gpu_request > 0 %>
            nvidia.com/gpu: <%= resource_constraint.gpu_request %>
            <% end %>
          <% end %>
        <% end %>
      imagePullSecrets:
      - name: dockerconfigjson-github-com
      <% if @project.volumes.present? %>
      volumes:
      <% project.volumes.each do |volume| %>
      - name: <%= volume.name %>
        persistentVolumeClaim:
          claimName: <%= volume.name %>
      <% end %>
      <% end %>
